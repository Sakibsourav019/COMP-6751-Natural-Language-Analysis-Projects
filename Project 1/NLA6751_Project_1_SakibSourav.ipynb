{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary lib, pckgs and loading the corpus"
      ],
      "metadata": {
        "id": "IQ23w31Lbpel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw6wBn8Q0uGE",
        "outputId": "74274d7c-0d22-489a-f370-aa4bd35e2781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INDONESIA UNLIKELY TO IMPORT PHILIPPINES COPRA\n",
            "  Indonesia is unlikely to import copra\n",
            "  from the Philippines in 1987 after importing 30,000 tonnes in\n",
            "  1986, the U.S. Embassy's annual agriculture report said.\n",
            "      The report said the 31 pct devaluation of the Indonesian\n",
            "  rupiah, an increase in import duties on copra and increases in\n",
            "  the price of Philippines copra have reduced the margin between\n",
            "  prices in the two countries.\n",
            "      Indonesia's copra production is forecast at 1.32 mln tonnes\n",
            "  in calendar 1987, up from 1.30 mln tonnes in 1986.\n",
            "  \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas\n",
        "import nltk\n",
        "#nltk.download('all') #run this line during the first time\n",
        "# nltk.download()\n",
        "\n",
        "# from nltk.book import\n",
        "from nltk.corpus import reuters\n",
        "\n",
        "\n",
        "# List the file IDs available in the Reuters corpus\n",
        "file_ids = reuters.fileids()\n",
        "\n",
        "# print(file_ids)\n",
        "# Access and print the content of a specific document (e.g., 'test/14826')\n",
        "document_id = 'training/267'\n",
        "document_content = reuters.raw(document_id)\n",
        "print(document_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Tokenization"
      ],
      "metadata": {
        "id": "pm7Q7O__AtbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(document_content)\n",
        "\n",
        "# Print the tokens\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQT2MTuL4mhY",
        "outputId": "391d3867-dbcb-4f3a-bf23-dcec2143d93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['INDONESIA', 'UNLIKELY', 'TO', 'IMPORT', 'PHILIPPINES', 'COPRA', 'Indonesia', 'is', 'unlikely', 'to', 'import', 'copra', 'from', 'the', 'Philippines', 'in', '1987', 'after', 'importing', '30,000', 'tonnes', 'in', '1986', ',', 'the', 'U.S.', 'Embassy', \"'s\", 'annual', 'agriculture', 'report', 'said', '.', 'The', 'report', 'said', 'the', '31', 'pct', 'devaluation', 'of', 'the', 'Indonesian', 'rupiah', ',', 'an', 'increase', 'in', 'import', 'duties', 'on', 'copra', 'and', 'increases', 'in', 'the', 'price', 'of', 'Philippines', 'copra', 'have', 'reduced', 'the', 'margin', 'between', 'prices', 'in', 'the', 'two', 'countries', '.', 'Indonesia', \"'s\", 'copra', 'production', 'is', 'forecast', 'at', '1.32', 'mln', 'tonnes', 'in', 'calendar', '1987', ',', 'up', 'from', '1.30', 'mln', 'tonnes', 'in', '1986', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to fix errors in Tokenization, I used RegexpTokenizer to detect apostrophes, abbreviations quotation marks and other special situations\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Define a regular expression pattern\n",
        "pattern = r'''(?x)             # Set flag to allow verbose regex\n",
        "    (?:[A-Z]\\.)+                # Abbreviations, e.g. U.S.A.\n",
        "    |\\d+(?:,\\d{3})*(?:\\.\\d+)?    # Numbers with optional commas and decimals\n",
        "    |\\w+(?:[-']\\w+)*            # Words with optional internal hyphens and apostrophes\n",
        "    |[.,;!?()]                  # Common punctuation\n",
        "    |(?:[...])                  # Ellipsis\n",
        "    |[“”‘’\"']                   # Quotation marks\n",
        "    |[\\[\\]{}:<>]                # Brackets and colons\n",
        "    |[—–-]                      # Dashes and hyphens\n",
        "    |[/]                        # Slashes\n",
        "    |(?:\\S)                     # Any other character (non-space)\n",
        "    \\$?\\d+(?:\\.\\d+)?%?          # CURRENCY AND PERCENTAGE\n",
        "'''\n",
        "\n",
        "# Create the tokenizer using the defined pattern\n",
        "tokenizer = RegexpTokenizer(pattern)\n",
        "\n",
        "\n",
        "# Tokenize the text using the tokenizer\n",
        "tokens = tokenizer.tokenize(document_content)\n",
        "\n",
        "# Print the tokens\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sOH7SPWAp-p",
        "outputId": "ad5c9063-ec45-4d53-caf0-f05729b864c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['INDONESIA', 'UNLIKELY', 'TO', 'IMPORT', 'PHILIPPINES', 'COPRA', 'Indonesia', 'is', 'unlikely', 'to', 'import', 'copra', 'from', 'the', 'Philippines', 'in', '1987', 'after', 'importing', '30,000', 'tonnes', 'in', '1986', ',', 'the', 'U.S.', \"Embassy's\", 'annual', 'agriculture', 'report', 'said', '.', 'The', 'report', 'said', 'the', '31', 'pct', 'devaluation', 'of', 'the', 'Indonesian', 'rupiah', ',', 'an', 'increase', 'in', 'import', 'duties', 'on', 'copra', 'and', 'increases', 'in', 'the', 'price', 'of', 'Philippines', 'copra', 'have', 'reduced', 'the', 'margin', 'between', 'prices', 'in', 'the', 'two', 'countries', '.', \"Indonesia's\", 'copra', 'production', 'is', 'forecast', 'at', '1.32', 'mln', 'tonnes', 'in', 'calendar', '1987', ',', 'up', 'from', '1.30', 'mln', 'tonnes', 'in', '1986', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Sentence Splitting"
      ],
      "metadata": {
        "id": "oSXbiquhG7-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use NLTK's sent_tokenize to split the passage into sentences\n",
        "from nltk import sent_tokenize\n",
        "sentences = sent_tokenize(document_content)\n",
        "\n",
        "# Print the sentences\n",
        "for i, sentence in enumerate(sentences):\n",
        "    print(f\"Sentence {i + 1}: {sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7x7s2qnHH4y",
        "outputId": "e85e8ca3-4766-4f31-eccc-23fbbe0f4d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: INDONESIA UNLIKELY TO IMPORT PHILIPPINES COPRA\n",
            "  Indonesia is unlikely to import copra\n",
            "  from the Philippines in 1987 after importing 30,000 tonnes in\n",
            "  1986, the U.S. Embassy's annual agriculture report said.\n",
            "Sentence 2: The report said the 31 pct devaluation of the Indonesian\n",
            "  rupiah, an increase in import duties on copra and increases in\n",
            "  the price of Philippines copra have reduced the margin between\n",
            "  prices in the two countries.\n",
            "Sentence 3: Indonesia's copra production is forecast at 1.32 mln tonnes\n",
            "  in calendar 1987, up from 1.30 mln tonnes in 1986.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Exclude the first sentence (i.e., the first line)"
      ],
      "metadata": {
        "id": "VqR4V0x4bgwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#APPROACH 1\n",
        "remaining_sentences = sentences[1: ]\n",
        "\n",
        "# Now you can work with the remaining sentences as needed\n",
        "for sentence in remaining_sentences:\n",
        "    print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvWu8SLlabGH",
        "outputId": "3171ff1f-764b-4dab-9bc6-fbaa8e838004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"INDONESIA UNLIKELY TO IMPORT PHILIPPINES COPRA\\n  Indonesia is unlikely to import copra\\n  from the Philippines in 1987 after importing 30,000 tonnes in\\n  1986, the U.S. Embassy's annual agriculture report said.\", 'The report said the 31 pct devaluation of the Indonesian\\n  rupiah, an increase in import duties on copra and increases in\\n  the price of Philippines copra have reduced the margin between\\n  prices in the two countries.', \"Indonesia's copra production is forecast at 1.32 mln tonnes\\n  in calendar 1987, up from 1.30 mln tonnes in 1986.\"]\n",
            "[\"INDONESIA UNLIKELY TO IMPORT PHILIPPINES COPRA\\n  Indonesia is unlikely to import copra\\n  from the Philippines in 1987 after importing 30,000 tonnes in\\n  1986, the U.S. Embassy's annual agriculture report said.\", 'The report said the 31 pct devaluation of the Indonesian\\n  rupiah, an increase in import duties on copra and increases in\\n  the price of Philippines copra have reduced the margin between\\n  prices in the two countries.', \"Indonesia's copra production is forecast at 1.32 mln tonnes\\n  in calendar 1987, up from 1.30 mln tonnes in 1986.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# APPROACH 2\n",
        "\n",
        "# Define the header phrase to exclude (assuming it's the first sentence)\n",
        "header_phrase = sentences[0]\n",
        "\n",
        "# Split the paragraph into sentences excluding the header phrase\n",
        "paragraph_sentences = [sentence for sentence in sentences if sentence != header_phrase]\n",
        "\n",
        "# Print the remaining sentences\n",
        "for sentence in paragraph_sentences:\n",
        "    print(sentence.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLIP9AiqkTwe",
        "outputId": "49b0f571-96ce-40bd-a0b7-b989d0f044a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The report said the 31 pct devaluation of the Indonesian\n",
            "  rupiah, an increase in import duties on copra and increases in\n",
            "  the price of Philippines copra have reduced the margin between\n",
            "  prices in the two countries.\n",
            "Indonesia's copra production is forecast at 1.32 mln tonnes\n",
            "  in calendar 1987, up from 1.30 mln tonnes in 1986.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. POS tagging"
      ],
      "metadata": {
        "id": "-pYEHzzeK3NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "\n",
        "# Tokenize the passage into words\n",
        "words = word_tokenize(document_content)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = pos_tag(words)\n",
        "\n",
        "# Print the POS tags\n",
        "for word, pos_tag in pos_tags:\n",
        "    print(f\"Word: {word}, POS Tag: {pos_tag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9D1bURsKaJv",
        "outputId": "da5a89f1-ffe7-4fc4-8599-ca9764fa7505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: INDONESIA, POS Tag: NNP\n",
            "Word: UNLIKELY, POS Tag: NNP\n",
            "Word: TO, POS Tag: NNP\n",
            "Word: IMPORT, POS Tag: NNP\n",
            "Word: PHILIPPINES, POS Tag: NNP\n",
            "Word: COPRA, POS Tag: NNP\n",
            "Word: Indonesia, POS Tag: NNP\n",
            "Word: is, POS Tag: VBZ\n",
            "Word: unlikely, POS Tag: JJ\n",
            "Word: to, POS Tag: TO\n",
            "Word: import, POS Tag: VB\n",
            "Word: copra, POS Tag: NN\n",
            "Word: from, POS Tag: IN\n",
            "Word: the, POS Tag: DT\n",
            "Word: Philippines, POS Tag: NNPS\n",
            "Word: in, POS Tag: IN\n",
            "Word: 1987, POS Tag: CD\n",
            "Word: after, POS Tag: IN\n",
            "Word: importing, POS Tag: VBG\n",
            "Word: 30,000, POS Tag: CD\n",
            "Word: tonnes, POS Tag: NNS\n",
            "Word: in, POS Tag: IN\n",
            "Word: 1986, POS Tag: CD\n",
            "Word: ,, POS Tag: ,\n",
            "Word: the, POS Tag: DT\n",
            "Word: U.S., POS Tag: NNP\n",
            "Word: Embassy, POS Tag: NNP\n",
            "Word: 's, POS Tag: POS\n",
            "Word: annual, POS Tag: JJ\n",
            "Word: agriculture, POS Tag: NN\n",
            "Word: report, POS Tag: NN\n",
            "Word: said, POS Tag: VBD\n",
            "Word: ., POS Tag: .\n",
            "Word: The, POS Tag: DT\n",
            "Word: report, POS Tag: NN\n",
            "Word: said, POS Tag: VBD\n",
            "Word: the, POS Tag: DT\n",
            "Word: 31, POS Tag: CD\n",
            "Word: pct, POS Tag: JJ\n",
            "Word: devaluation, POS Tag: NN\n",
            "Word: of, POS Tag: IN\n",
            "Word: the, POS Tag: DT\n",
            "Word: Indonesian, POS Tag: NNP\n",
            "Word: rupiah, POS Tag: NN\n",
            "Word: ,, POS Tag: ,\n",
            "Word: an, POS Tag: DT\n",
            "Word: increase, POS Tag: NN\n",
            "Word: in, POS Tag: IN\n",
            "Word: import, POS Tag: JJ\n",
            "Word: duties, POS Tag: NNS\n",
            "Word: on, POS Tag: IN\n",
            "Word: copra, POS Tag: NN\n",
            "Word: and, POS Tag: CC\n",
            "Word: increases, POS Tag: NNS\n",
            "Word: in, POS Tag: IN\n",
            "Word: the, POS Tag: DT\n",
            "Word: price, POS Tag: NN\n",
            "Word: of, POS Tag: IN\n",
            "Word: Philippines, POS Tag: NNPS\n",
            "Word: copra, POS Tag: NNS\n",
            "Word: have, POS Tag: VBP\n",
            "Word: reduced, POS Tag: VBN\n",
            "Word: the, POS Tag: DT\n",
            "Word: margin, POS Tag: NN\n",
            "Word: between, POS Tag: IN\n",
            "Word: prices, POS Tag: NNS\n",
            "Word: in, POS Tag: IN\n",
            "Word: the, POS Tag: DT\n",
            "Word: two, POS Tag: CD\n",
            "Word: countries, POS Tag: NNS\n",
            "Word: ., POS Tag: .\n",
            "Word: Indonesia, POS Tag: NNP\n",
            "Word: 's, POS Tag: POS\n",
            "Word: copra, POS Tag: NN\n",
            "Word: production, POS Tag: NN\n",
            "Word: is, POS Tag: VBZ\n",
            "Word: forecast, POS Tag: VBN\n",
            "Word: at, POS Tag: IN\n",
            "Word: 1.32, POS Tag: CD\n",
            "Word: mln, POS Tag: NN\n",
            "Word: tonnes, POS Tag: NNS\n",
            "Word: in, POS Tag: IN\n",
            "Word: calendar, POS Tag: NN\n",
            "Word: 1987, POS Tag: CD\n",
            "Word: ,, POS Tag: ,\n",
            "Word: up, POS Tag: RB\n",
            "Word: from, POS Tag: IN\n",
            "Word: 1.30, POS Tag: CD\n",
            "Word: mln, POS Tag: NN\n",
            "Word: tonnes, POS Tag: NNS\n",
            "Word: in, POS Tag: IN\n",
            "Word: 1986, POS Tag: CD\n",
            "Word: ., POS Tag: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Gazetteer Annotation"
      ],
      "metadata": {
        "id": "qHPmKbpxOUAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = nltk.word_tokenize(document_content)\n",
        "\n",
        "# Define gazetteers\n",
        "countries = [\"INDONESIA\", \"PHILIPPINES\"]\n",
        "currencies = [\"rupiah\", \"pct\"]\n",
        "units = [\"tonnes\", \"mln\"]\n",
        "\n",
        "# Create regular expression patterns for each category\n",
        "country_pattern = r'\\b(?:' + '|'.join(re.escape(country) for country in countries) + r')\\b'\n",
        "currency_pattern = r'\\b(?:' + '|'.join(re.escape(currency) for currency in currencies) + r')\\b'\n",
        "unit_pattern = r'\\b(?:' + '|'.join(re.escape(unit) for unit in units) + r')\\b'\n",
        "\n",
        "# Define chunking rules using regular expressions\n",
        "chunk_grammar = r\"\"\"\n",
        "    COUNTRY: {<NNP>{1,}}\n",
        "    CURRENCY: {<NN><NN><NN><NN>?}\n",
        "    UNIT: {<NN><NN><NN><NN>?}\n",
        "\"\"\"\n",
        "\n",
        "# Create a chunk parser with the defined grammar\n",
        "chunk_parser = nltk.RegexpParser(chunk_grammar)\n",
        "\n",
        "# Tag the words with part-of-speech tags\n",
        "pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "# Parse the tagged words using the chunk parser\n",
        "chunks = chunk_parser.parse(pos_tags)\n",
        "\n",
        "# Function to annotate chunks\n",
        "def annotate_chunks(tree, pattern, annotation):\n",
        "    for subtree in tree.subtrees():\n",
        "        if re.search(pattern, subtree.leaves()[0][0], re.IGNORECASE):\n",
        "            subtree.set_label(annotation)\n",
        "\n",
        "# Annotate chunks with gazetteer information\n",
        "annotate_chunks(chunks, country_pattern, \"COUNTRY\")\n",
        "annotate_chunks(chunks, currency_pattern, \"CURRENCY\")\n",
        "annotate_chunks(chunks, unit_pattern, \"UNIT\")\n",
        "\n",
        "# Print the annotated chunks\n",
        "for subtree in chunks.subtrees():\n",
        "    if subtree.label():\n",
        "        print(subtree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn3KKIEqObPA",
        "outputId": "75f81d05-73a8-4aaa-abac-94fd194da9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(COUNTRY\n",
            "  (COUNTRY\n",
            "    INDONESIA/NNP\n",
            "    UNLIKELY/NNP\n",
            "    TO/NNP\n",
            "    IMPORT/NNP\n",
            "    PHILIPPINES/NNP\n",
            "    COPRA/NNP\n",
            "    Indonesia/NNP)\n",
            "  is/VBZ\n",
            "  unlikely/JJ\n",
            "  to/TO\n",
            "  import/VB\n",
            "  copra/NN\n",
            "  from/IN\n",
            "  the/DT\n",
            "  Philippines/NNPS\n",
            "  in/IN\n",
            "  1987/CD\n",
            "  after/IN\n",
            "  importing/VBG\n",
            "  30,000/CD\n",
            "  tonnes/NNS\n",
            "  in/IN\n",
            "  1986/CD\n",
            "  ,/,\n",
            "  the/DT\n",
            "  (COUNTRY U.S./NNP Embassy/NNP)\n",
            "  's/POS\n",
            "  annual/JJ\n",
            "  agriculture/NN\n",
            "  report/NN\n",
            "  said/VBD\n",
            "  ./.\n",
            "  The/DT\n",
            "  report/NN\n",
            "  said/VBD\n",
            "  the/DT\n",
            "  31/CD\n",
            "  pct/JJ\n",
            "  devaluation/NN\n",
            "  of/IN\n",
            "  the/DT\n",
            "  (COUNTRY Indonesian/NNP)\n",
            "  rupiah/NN\n",
            "  ,/,\n",
            "  an/DT\n",
            "  increase/NN\n",
            "  in/IN\n",
            "  import/JJ\n",
            "  duties/NNS\n",
            "  on/IN\n",
            "  copra/NN\n",
            "  and/CC\n",
            "  increases/NNS\n",
            "  in/IN\n",
            "  the/DT\n",
            "  price/NN\n",
            "  of/IN\n",
            "  Philippines/NNPS\n",
            "  copra/NNS\n",
            "  have/VBP\n",
            "  reduced/VBN\n",
            "  the/DT\n",
            "  margin/NN\n",
            "  between/IN\n",
            "  prices/NNS\n",
            "  in/IN\n",
            "  the/DT\n",
            "  two/CD\n",
            "  countries/NNS\n",
            "  ./.\n",
            "  (COUNTRY Indonesia/NNP)\n",
            "  's/POS\n",
            "  copra/NN\n",
            "  production/NN\n",
            "  is/VBZ\n",
            "  forecast/VBN\n",
            "  at/IN\n",
            "  1.32/CD\n",
            "  mln/NN\n",
            "  tonnes/NNS\n",
            "  in/IN\n",
            "  calendar/NN\n",
            "  1987/CD\n",
            "  ,/,\n",
            "  up/RB\n",
            "  from/IN\n",
            "  1.30/CD\n",
            "  mln/NN\n",
            "  tonnes/NNS\n",
            "  in/IN\n",
            "  1986/CD\n",
            "  ./.)\n",
            "(COUNTRY\n",
            "  INDONESIA/NNP\n",
            "  UNLIKELY/NNP\n",
            "  TO/NNP\n",
            "  IMPORT/NNP\n",
            "  PHILIPPINES/NNP\n",
            "  COPRA/NNP\n",
            "  Indonesia/NNP)\n",
            "(COUNTRY U.S./NNP Embassy/NNP)\n",
            "(COUNTRY Indonesian/NNP)\n",
            "(COUNTRY Indonesia/NNP)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "ZoFXYJhhVrh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ne_chunk\n",
        "\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = word_tokenize(document_content)\n",
        "\n",
        "# Perform NER\n",
        "ner_tags = ne_chunk(nltk.pos_tag(words))\n",
        "\n",
        "# Print the named entities\n",
        "for subtree in ner_tags:\n",
        "    if isinstance(subtree, nltk.Tree):\n",
        "        entity = \" \".join([word for word, tag in subtree.leaves()])\n",
        "        label = subtree.label()\n",
        "        print(f\"Entity: {entity}, Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvwz3KrAVvfl",
        "outputId": "d89cd9c0-2e57-4a6e-ea16-d3f97b57846f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: INDONESIA, Label: GPE\n",
            "Entity: UNLIKELY, Label: ORGANIZATION\n",
            "Entity: IMPORT, Label: ORGANIZATION\n",
            "Entity: Indonesia, Label: GPE\n",
            "Entity: Philippines, Label: ORGANIZATION\n",
            "Entity: U.S., Label: GPE\n",
            "Entity: Embassy, Label: ORGANIZATION\n",
            "Entity: Indonesian, Label: GPE\n",
            "Entity: Philippines, Label: GSP\n",
            "Entity: Indonesia, Label: GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Measured Entity Recognition (MER)"
      ],
      "metadata": {
        "id": "kXA_A0LgWOKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Use regular expressions to find measurements with commas and group them\n",
        "measurements = re.findall(r'(\\d{1,3}(,\\d{3})*(\\.\\d+)?\\s*(mln|pct|tonnes))', document_content)\n",
        "\n",
        "# Print the measurements found\n",
        "for measurement in measurements:\n",
        "    value, _, _, unit = measurement\n",
        "    print(f\"Value: {value}, Unit: {unit}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSHOH8ToWCAb",
        "outputId": "5a0f45a5-154f-4353-98a0-f35f50e84cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: 30,000 tonnes, Unit: tonnes\n",
            "Value: 31 pct, Unit: pct\n",
            "Value: 1.32 mln, Unit: mln\n",
            "Value: 1.30 mln, Unit: mln\n"
          ]
        }
      ]
    }
  ]
}